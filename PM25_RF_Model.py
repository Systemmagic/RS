import pandas as pd
import numpy as np
import joblib  # ç”¨äºä¿å­˜æ¨¡å‹
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set(style="whitegrid")
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Microsoft YaHei'] 
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·


# ================= 1. æ•°æ®å‡†å¤‡ =================
print("ğŸš€ Step 1: åŠ è½½è®­ç»ƒæ•°æ®...")
try:
    df = pd.read_csv('Final_Training_Dataset.csv')
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œæ€»æ ·æœ¬é‡: {len(df)}")
except FileNotFoundError:
    print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° Final_Training_Dataset.csvï¼Œè¯·å…ˆè¿è¡Œæ•°æ®åˆå¹¶è„šæœ¬ã€‚")
    exit()

# å®šä¹‰ç‰¹å¾ (X) å’Œ æ ‡ç­¾ (y)
# æ³¨æ„ï¼šä¸€å®šè¦å’Œ GEE å¯¼å‡ºçš„åˆ—åä¿æŒä¸€è‡´
feature_cols = ['AOD_055', 'TEMP_C', 'WIND_SPEED', 'PRESSURE_HPA', 'RAIN_MM']
target_col = 'PM25'

X = df[feature_cols]
y = df[target_col]

# åˆ’åˆ†æ•°æ®é›† (80% è®­ç»ƒ, 20% æµ‹è¯•)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)#random_state = 42)

print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)}, æµ‹è¯•é›†å¤§å°: {len(X_test)}")

# ================= 2. æ¨¡å‹è®­ç»ƒ =================
print("\nğŸš€ Step 2: è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ (Random Forest)...")

# åˆå§‹åŒ–æ¨¡å‹
# n_estimators: æ ‘çš„æ•°é‡ï¼Œè¶Šå¤šé€šå¸¸è¶Šç¨³ï¼Œä½†è¶Šæ…¢
# max_depth: æ ‘çš„æ·±åº¦ï¼Œé™åˆ¶æ·±åº¦é˜²æ­¢è¿‡æ‹Ÿåˆ
# n_jobs=-1: è°ƒç”¨æ‰€æœ‰ CPU æ ¸å¿ƒåŠ é€Ÿ
rf_model = RandomForestRegressor(n_estimators=300, 
                                 max_depth=20, 
                                 min_samples_split=5, 
                                 min_samples_leaf=2,
                                 random_state=42, 
                                 n_jobs=-1)

# æ‹Ÿåˆæ•°æ®
rf_model.fit(X_train, y_train)
print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

# ================= 3. æ¨¡å‹è¯„ä¼° =================
print("\nğŸš€ Step 3: æ¨¡å‹æ€§èƒ½è¯„ä¼°")

# é¢„æµ‹
y_pred_train = rf_model.predict(X_train)
y_pred_test = rf_model.predict(X_test)

# è®¡ç®—æŒ‡æ ‡
def evaluate(y_true, y_pred, name):
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    print(f"[{name}] RÂ²: {r2:.3f} | RMSE: {rmse:.3f} | MAE: {mae:.3f}")
    return r2

r2_train = evaluate(y_train, y_pred_train, "è®­ç»ƒé›†")
r2_test = evaluate(y_test, y_pred_test, "æµ‹è¯•é›† (CV)")

# ================= 4. ç»“æœå¯è§†åŒ– =================
print("\nğŸš€ Step 4: ç”Ÿæˆè¯„ä¼°å›¾è¡¨...")

plt.figure(figsize=(14, 6))

# å›¾ 1: ç‰¹å¾é‡è¦æ€§
plt.subplot(1, 2, 1)
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]
sns.barplot(x=importances[indices], y=[feature_cols[i] for i in indices], palette="viridis")
plt.title("å˜é‡é‡è¦æ€§ (Feature Importance)")
plt.xlabel("ç›¸å¯¹é‡è¦æ€§")

# å›¾ 2: æ•£ç‚¹æ‹Ÿåˆå›¾ (åªç”»æµ‹è¯•é›†)
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_test, color='#3498db', alpha=0.6, label='Test Samples')
# ç”» 1:1 çº¿
min_val = min(y_test.min(), y_pred_test.min())
max_val = max(y_test.max(), y_pred_test.max())
plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='1:1 Line')
plt.xlabel(r'åœ°é¢ç›‘æµ‹ PM2.5 ($ \mu g / m^3 $)')
plt.ylabel(r'æ¨¡å‹åæ¼” PM2.5 ($ \mu g / m^3 $)')
plt.title(f'æ¨¡å‹ç²¾åº¦éªŒè¯ ($R^2={r2_test:.2f}$)')
plt.legend()
plt.tight_layout()
plt.show()

# ================= 5. ä¿å­˜æ¨¡å‹ =================
# å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°ï¼Œä»¥ä¾¿ä¸‹ä¸€æ­¥ç”Ÿæˆåœ°å›¾æ—¶ç›´æ¥è°ƒç”¨
model_filename = 'PM25_RF_Model.joblib'
joblib.dump(rf_model, model_filename)
print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜ä¸º: {model_filename}")
print("ä¸‹ä¸€æ­¥ï¼šä¸‹è½½åŒºåŸŸé¥æ„Ÿå½±åƒï¼Œä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œç©ºé—´åˆ¶å›¾ï¼")
